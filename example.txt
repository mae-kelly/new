-- APPROACH 1A: Batch processing solution to avoid size limits
-- Processes tables in smaller batches to avoid the 1MB script variable limit

-- Create a permanent table to store results
CREATE OR REPLACE TABLE `prj-fisv-p-gcss-sas-d19dd0f1df.CSIRT.table_column_samples` (
  project_id STRING,
  dataset_id STRING,
  table_name STRING,
  column_name STRING,
  data_type STRING,
  sample_values ARRAY<STRING>
);

-- Get unique tables first
CREATE OR REPLACE TEMP TABLE unique_tables AS
SELECT DISTINCT
  table_catalog as project_id,
  table_schema as dataset_id,
  table_name,
  ROW_NUMBER() OVER (ORDER BY table_catalog, table_schema, table_name) as table_num
FROM `prj-fisv-p-gcss-sas-d19dd0f1df.INFORMATION_SCHEMA.COLUMNS`
WHERE table_schema NOT IN ('INFORMATION_SCHEMA', 'information_schema');

-- Process tables in batches (adjust batch_size as needed)
DECLARE batch_size INT64 DEFAULT 10;
DECLARE max_table_num INT64;
DECLARE current_batch_start INT64 DEFAULT 1;
DECLARE current_batch_end INT64;

SET max_table_num = (SELECT MAX(table_num) FROM unique_tables);

-- Loop through batches
WHILE current_batch_start <= max_table_num DO
  SET current_batch_end = LEAST(current_batch_start + batch_size - 1, max_table_num);
  
  -- Process current batch of tables
  FOR record IN (
    SELECT DISTINCT project_id, dataset_id, table_name
    FROM unique_tables 
    WHERE table_num BETWEEN current_batch_start AND current_batch_end
  ) DO
    -- Process each table in the current batch
    FOR col_record IN (
      EXECUTE IMMEDIATE FORMAT("""
        SELECT column_name, data_type
        FROM `%s.INFORMATION_SCHEMA.COLUMNS`
        WHERE table_catalog = '%s' 
          AND table_schema = '%s' 
          AND table_name = '%s'
        ORDER BY ordinal_position
      """, record.project_id, record.project_id, record.dataset_id, record.table_name)
    ) DO
      -- Sample data for each column
      EXECUTE IMMEDIATE FORMAT("""
        INSERT INTO `prj-fisv-p-gcss-sas-d19dd0f1df.CSIRT.table_column_samples`
        SELECT 
          '%s' as project_id,
          '%s' as dataset_id,
          '%s' as table_name,
          '%s' as column_name,
          '%s' as data_type,
          ARRAY_AGG(CAST(%s AS STRING) IGNORE NULLS LIMIT 5) as sample_values
        FROM `%s.%s.%s`
        WHERE %s IS NOT NULL
        HAVING COUNT(*) > 0
      """, 
      record.project_id, record.dataset_id, record.table_name, 
      col_record.column_name, col_record.data_type, col_record.column_name,
      record.project_id, record.dataset_id, record.table_name, 
      col_record.column_name);
    END FOR;
  END FOR;
  
  SET current_batch_start = current_batch_end + 1;
END WHILE;

-- Final result
SELECT * FROM `prj-fisv-p-gcss-sas-d19dd0f1df.CSIRT.table_column_samples`
ORDER BY project_id, dataset_id, table_name, column_name;

-- =============================================================================
-- APPROACH 2: Schema discovery with generated sampling queries
-- Use this if you prefer to run the sampling queries manually
-- =============================================================================

/*
-- Step 1: Get all table and column information
SELECT 
  table_catalog as project_id,
  table_schema as dataset_id,
  table_name,
  column_name,
  data_type,
  ordinal_position,
  -- Generate sampling query for each column
  CONCAT(
    'SELECT "', table_catalog, '.' , table_schema, '.', table_name, '" as table_full_name, ',
    '"', column_name, '" as column_name, ',
    'ARRAY_AGG(CAST(', column_name, ' AS STRING) IGNORE NULLS LIMIT 5) as sample_values ',
    'FROM `', table_catalog, '.', table_schema, '.', table_name, '` ',
    'WHERE ', column_name, ' IS NOT NULL'
  ) as sampling_query
FROM 
  `your_project.your_dataset.INFORMATION_SCHEMA.COLUMNS`
WHERE 
  table_schema NOT IN ('INFORMATION_SCHEMA', 'information_schema')
ORDER BY 
  table_catalog, table_schema, table_name, ordinal_position;
*/

-- =============================================================================
-- APPROACH 3: Quick schema overview without samples
-- Use this for a fast overview of all tables and columns
-- =============================================================================

/*
SELECT 
  table_catalog as project_id,
  table_schema as dataset_id,
  table_name,
  COUNT(*) as column_count,
  STRING_AGG(CONCAT(column_name, ' (', data_type, ')'), ', ' ORDER BY ordinal_position) as columns
FROM 
  `your_project.your_dataset.INFORMATION_SCHEMA.COLUMNS`
WHERE 
  table_schema NOT IN ('INFORMATION_SCHEMA', 'information_schema')
GROUP BY 
  table_catalog, table_schema, table_name
ORDER BY 
  project_id, dataset_id, table_name;
*/